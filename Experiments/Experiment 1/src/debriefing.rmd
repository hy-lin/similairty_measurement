---
title: "Debriefing"
author: "Hsuan-Yu Lin"
date: "8 November 2016"
output: html_document
bibliography: bibliography.bib
csl: apa-annotated-bibliography.csl
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

Please make sure your participant ID is correct in order to load your data file. 
```{r input.pID}
pID <- 123
```
Really, check your participant ID.

```{r load.dara, echo = FALSE}
pair_dist_matrix <- as.matrix(read.table(sprintf('Data/SimilarityMatrix/PairWise_%03d_01.dat', pID), sep = '\t'))
pair_dist_matrix <- pair_dist_matrix[,-ncol(pair_dist_matrix)]
multi_dist_matrix <- as.matrix(read.table(sprintf('Data/SimilarityMatrix/MultiItemsArrangement_%03d_01.dat', pID), sep = '\t'))
multi_dist_matrix <- multi_dist_matrix[,-ncol(multi_dist_matrix)]
```

## Experiment Object
This experiment is developed to test a new method of measuring the similarity matrix between items [@nosofsky1992similarity]. Traditionally, in order to measure the similarity matrix, experimenters and participants have to go through a lengthy procedure in order to acquire the similarity matrix [@MDS4Psychology]. One of the commonly used procedure is the second part of this experiment, Pair-Wise Comparison: Experimenters show participants two items and ask participants about the similarity between said items. 

### Pair-Wise Comparison

This traditional __Pair-Wise Comparison__ method ensures the similarity between all the possible pairs are measured. However, the required number of trials is as 
$$\binom{n}{2} = \frac{n(n-1)}{2}$$
when $n$ is the number of items. The number of trials increases as power function of $n$. If the total number of items is $10$, you need $45$ trials to acquire the similarity matrix. If the number of items is $50$, a participant has to go through 

``` {r do.the.math}
50 * (50-1) / 2
```
this amount of trials. This amount of trials would require about two hours to complete. It's very painful and boring for participants and is very very costly just to acquire the similarity matrix.

In this experiment, we used $16$ items. This means there will be

``` {r do.more.math}
16 * (16-1) / 2
```
number of trials. This is still under manageable number, since we don't want to torture you.

### Multi-Items Arrangement
In this experiment, we tried a new method to measure the similarity matrix: __Multi-Items Arrangement__. Instead of comparing two items in each trials, Multi-Items Arrangement method allows multiple items being compared at once, which reduced the number of trials dramatically. Assuming $k$ items are compared once, and there are totally $n$ items. The required number of trials is 
$$\binom{\frac{2n}{k}}{2} = \frac{(2n/k)*(2n/k-1)}{2}.$$
So if we present $4$ items at once, and the total number of items is $10$. The number of trials is $10$. If the number of items is $50$, a participant has to go through
``` {r do.the.math.again}
(50*2/4) * (50*2/4 - 1) / 2
```
This is much better than what we had with pair-wise comparison. If we present $10$ items at once, the number became:
``` {r do.the.math.third}
(50*2/10) * (50*2/10 - 1) / 2
```
This is easily manageable. The more items we present at once, the less trials are required to acquire the similarity matrix.

However, this is not a well-tested method. We want to ensure the Multi-Items Arrangement method can measure the similarity matrix accurately and reliably. So we test the Multi-Items Arrangement method along with Pair-Wise Comparison method and compare the similarity matrices acquired by both method. If the similarity matrices converge, we feel more confident about the Multi-Items Arrangement method.

In this experiment, we presetned $8$ items at once, so the total number of trials is:
``` {r}
(16*2/8) * (16*2/8 - 1) / 2
```

## Your Result
Here we show you the result from your response.

### Multi-Items Arrangement
``` {r prepare.plot.multi.item.arrangement.result, echo=FALSE}
multi_loc <- cmdscale(multi_dist_matrix)
multi.scale <- 1.5/(max(multi_loc) - min(multi_loc))
multi.x = multi_loc[, 1] * multi.scale
multi.y = multi_loc[, 2] * multi.scale
```
``` {r plot.multi.item.arrangement.result}
plot(multi.x, multi.y, type = 'n', xlim = c(-1, 1), ylim = c(-1, 1))
text(multi.x, multi.y, colnames(multi_dist_matrix), cex=.6, col = 'black')
```

This is your similarity matrix measured by multi-items arrangement method. To visualize the similarity matrix, we used [Multidimensional Scaling](https://en.wikipedia.org/wiki/Multidimensional_scaling) to consolidate the result into a two-dimensional plot. The distance between items indicates the similarity between items, which is just the same as we asked you to do in the multi-items arrangement method. You can interpret the plot as where you would put all the items on the screen in a multi-items arrangement trial. 

### Pair-Wise Comparison
```{r prepare.plot.pair.wise.comparison.result, echo=FALSE}
pair_loc <- cmdscale(pair_dist_matrix)
pair.scale <- 1.5/(max(pair_loc)-min(pair_loc))
pair.x = pair_loc[, 1] * pair.scale
pair.y = pair_loc[, 2] * pair.scale
```
``` {r plot.pair.wise.comparison.result}
plot(pair.x, pair.y, type = 'n', xlim = c(-1, 1), ylim = c(-1, 1))
text(pair.x, pair.y, colnames(pair_dist_matrix), cex=.6, col = 'red')
```

This is the similarity matrix acquired by pair-wise comparison method. Again, we used MDS to visualize the similarity matrix. If you are lucky, you will see the similarity matrices acquired from multi-items arrangement method and the pair-wise comparison method are very similar to each other. But in some cases, they are different from each other. This is mostly because MDS might rotating and mirroring the similarity matrix, thus results in different plots. 

Here you go, this is the result generated from your data.

# References
